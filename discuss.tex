\chapter{Discussion}
\label{chap:discuss}

\section{Contribution}

Research in the area of emotional intelligence generally covers the following four aspects: (1) \textit{recognition of affective states}, (2) \textit{generation of affectively modulated signals}, (3) \textit{psychological study of human emotions}, and (4) \textit{computationally modelling affective HCIs}. While studies covering one or more of these aspects have been conducted, few assistive systems that have integrated all the four pieces together have been implemented. This thesis is one of the exploratory works in this area and proposed a solution to integrating emotional intelligence with a cognitive intelligent assistive system. 

This thesis defined four objectives at the beginning and sought solutions to achieve it. It reviewed previous work in all the four aspects of emotional intelligence, and designed and implemented a prototypical hand-washing system aimed at assisting people with dementia to complete hand-washing tasks successfully. As an integration of independent components, the hand-washing system is extensible and portable. The hand-washing system is able to run in real-time from the perspective of the user group, and has been shown by laboratory tests that it is capable of providing a level of functional assistance and producing system prompts that have encoded to some extent the emotional state of the user.

Approaches that can be taken to recognize affective meanings of user behaviours in the application scenario, and the difficulties that lie in those approaches have been discussed in the thesis. The author pointed out that constrained by the specialty of the hand-washing scenario and the user group of this application, vision-based approaches focusing on facial expression analysis and acoustic-based approaches, which are the two most common approaches in affect recognition, are not necessarily the most suitable solutions for recognizing affective meanings of user behaviours for this particular application. The thesis finally took an initial threshold-based approach of recognizing affective meanings of user behaviours from hand movements - to be more specific, the expansiveness between user's hands and the velocity of the user moving his/her hands. The tracker that was used to locate the user's hands was designed and implemented as an extension to an existing human body tracker \cite{czarnuch2014}.

The affective reasoning during interactions are implemented in a reasoning engine where belief state of the user's affective identities is updated basing upon BayesACT. The engine also maintains a belief state of how much the user has completed in the hand-washing process. Recommendation of prompts described in both functional (i.e. the content of an instructional message) and emotional (i.e. how the instructional message should be expressed) dimensions are produced by the engine based on the belief states and certain policies. The engine was designed and implemented on the basis of the existing BayesAct framework \cite{hoey2013bayesian}.

To enable the prompting system to display affectively modulated prompts to users, the thesis also reviewed techniques used in affective signal generation. Since dynamic generation of prompts is relatively difficult and requires much computational resources, the thesis took an approach of selecting the final prompt from a set of pre-generated and evaluated prompts. This thesis summarized that the four most essential questions involved in designing a prompt dataset and choosing a most appropriate one from it are: (1) Deciding the format of the prompts: should they be video, audio, or textual prompt? (2) Designing the prompts, e.g. the words used in the prompts. If the prompts are audio or video prompts, the tones how the messages are stated should be carefully designed as well. Character gestures and other details might require considerations as well if video prompts are used. (3) Labelling the generated prompts. (4) Selecting the prompt to display based on the propositional and emotional descriptions of recommended prompts produced by the reasoning engine. After these questions were discussed, the hand-washing system was designed and implemented in a way to select the final prompts displayed to users from a set of prompts generated and evaluated in previous work \cite{malhotra2014}. The final prompts were selected based on two conditions: (1) it should have same functional meanings as the recommended prompt by the engine, and (2) among all the prompts in the set that satisfy the first condition, it should have the smallest emotional distance, whose definition was defined in the thesis, to the recommended prompt.

Preliminary experiments where the system monitors an actor washing her hands and gives prompts were conducted. The results of two tests, where the actor behaved less powerfully and less actively in the second test than in the first, were described and compared in details in the thesis. 15 other tests of the system were conducted as well. A simple comparison of the averages of EPA values for user behaviours, the user's identities and system prompts are provided in the thesis. Detailed state changes in those experiments are provided in the appendix of the thesis. The results of the tests showed that user behaviours are roughly recognized by the system, the EPA values computed for the user behaviours are reasonable. The tests also showed that the system is able to update its beliefs of planstep and emotional state of the user, and is able to produce accordingly system prompts both functionally and emotionally. The tests also indicated that user behaviours with higher P and higher A values are more likely to lead to identity beliefs for the user with higher P and higher A values and system prompts with lower P and higher A values.


\section{Future Work}

This thesis is an initial work of integrating emotional intelligence with intelligent cognitive assistants. Our prototypical system is a first approach in this exploratory area and focuses on the integration work of combining different pieces of emotional intelligences with real-world functional assistive systems. The system may be improved in the following multiple directions:

\begin{enumerate}

\item{Improving the EPA-Calculator}

Currently, the system computes the affective meanings embedded in user behaviours based on the expansiveness of the user's hands and the velocity of the user's hand movements. By cooperating with sociologists, psychologists, and physiologists, and studying the relationships between the behaviours of persons with AD and their emotion changes, more sophisticated features/indicators may be chosen to recognize the user's emotional states. If new features are chosen, new sensors and analyzers that obtain the selected features from observations might need to be added to the system .

Data collection and labelling is needed as well to implement a sophisticated EPA-Calculator. Data can be collected by recording videos of a person's hand movements while he/she is washing his/her hands. Ideally, the behaviours of persons with dementia should be recorded in order to achieve better performance for the calculator. The number of video recordings should be designed carefully. It is desirable that the recordings cover all possibilities that how a person's emotion changes during the handwashing process, though, unfortunately, it is infeasible to achieve this in reality due to the subjective nature of emotional experiences. After videos recording people's hand movements while they are washing their hands are collected, surveys should be conducted to get these them labelled. Note that videos should be cut into shorter clips before they are labelled. This process is called data segmentation and is itself an open-ended problem. With proper segmentation, the user's emotional states (or the general emotional impressions formed by the clip) should remain stable throughout a video clip. For each short clip, a single EPA vector representing emotional impression the participant has on the clip is collected and is associated with each frame within the clip. Apparently, the time length of the video clips should not be either too long nor too short. If the video clips are too long, more than one emotions are likely to be presented by a same clip. If the video clips are too short, human raters might not be able to differentiate the emotional impressions presented by one clip from that presented by another. A solution that avoids that difficult data segmentation problem is to present the whole videos to participants, and let the participants to split and assign new EPA values to clips when they feel a new emotional impression is formed. This approach is easier to implement, with the risks of people partitioning the videos differently and unreasonably. Other aspects of the survey, such as participant eligibility for the survey, should be designed carefully as well. If the data collected and labelled is not enough, which often happens in medical research, statistical methods, such as bootstrapping, can be applied. 

Even though labelling was conducted on video clips, the labels are applied to frames within the videos, and models mapping from features extracted from the frames to the labels are trained. This is to avoid the heavy computational burden caused by learning directly from videos. Note that several frames are produced from a single video clip, and not all of them need to be included in the training process. Decisions should be made on when, how many, and what frames to cut from the video clips for training. The shorter the time period between two neighbour frames, the more accurate the result would be. However, it would require too much computational resources if neighbouring frames are too close to each other. If the frames are grabbed at a frequency higher than that at which frames are processed by the classifier, loss of data would occur as well.

\item{Improving the prompt generation process}

Currently, the system selected final prompts displayed to users from a set of 30 audio-visual prompts generated and evaluated in Malhotra's work \cite{malhotra2014}. The prompts were evaluated in terms of EPA values in a survey where participants were normal healthy persons. More prompts with different formats and contents can be created, rated and added to the prompt dataset in the future. Moreover, if the system were to experiment in clinical trials (as opposed to in the laboratory environment), the prompt dataset should be rated by persons with AD rather than normal healthy persons. Approaches that can dynamically generate prompts could be tried as well in future works.

\item{Improving the Planstep- and Emotion- Updater}

Currently, the belief states updater of the system is implemented as a POMDP. It assumes that the user and the system take turns in the interactions. Future work can improve the system by breaking through the turn-taking limits. The user's identity is learned by a BayesACT model in the current approach. Further investigation of identities in Alzheimer's disease and how BayesACT can be used to provide more effective prompting can be taken in future work as well.

\item{Conducting clinical trials for the system}

With training and testing data collected from clinical trials, and data labelled and prompts evaluated by persons with AD, preliminary tests of the system in clinical environments can be conducted in future works.

\end{enumerate}

Being designed and implemented as an integration of independent components, the system is extensible and portable, which makes it possible to improve one or more of the components with a few, if any, minor changes to other components.

